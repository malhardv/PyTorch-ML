{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 00. Pytorch Fundamentals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing modules\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Tensors\n",
    "# Creating Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scalar\n",
    "scalar = torch.tensor(7)\n",
    "scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get scalar back as pythong int\n",
    "scalar.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 7])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vector\n",
    "vector = torch.tensor([7, 7])\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5, 5],\n",
       "        [5, 5]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MATRIX\n",
    "MATRIX = torch.tensor([[5, 5],\n",
    "                       [5, 5]])\n",
    "MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3],\n",
       "         [4, 5, 6],\n",
       "         [7, 8, 9]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TENSOR\n",
    "TENSOR = torch.tensor([[[1, 2, 3],\n",
    "                        [4, 5, 6],\n",
    "                        [7, 8, 9]]])\n",
    "TENSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 3])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR.shape   # means that we have only 3x3 dimension tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6],\n",
       "        [7, 8, 9]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 5, 6])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR[0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR[0, 1, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Tensors\n",
    "Why Random Tensors? RT because the way many neural networks learn is that they start with tensors full of random numbers and the adjust those numbers to better represent the data. Start with random numbers -> look at the data -> update random numbers -> look at data -> update random numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3930, 0.1484, 0.0696, 0.5799],\n",
       "        [0.6540, 0.7560, 0.5420, 0.0495],\n",
       "        [0.1980, 0.7815, 0.9714, 0.6073]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a Random Tensor of size (3, 4)\n",
    "random_tensor = torch.rand(3, 4)\n",
    "random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.4119, 0.3860, 0.4481, 0.3153],\n",
       "         [0.9018, 0.0831, 0.1493, 0.8636],\n",
       "         [0.0385, 0.5544, 0.3826, 0.4121]]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "another_random_tensor = torch.rand(1, 3, 4)\n",
    "another_random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "another_random_tensor.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.1186, 0.9115, 0.1671],\n",
       "         [0.5388, 0.3910, 0.8491],\n",
       "         [0.8785, 0.2504, 0.9269],\n",
       "         ...,\n",
       "         [0.0591, 0.0645, 0.4383],\n",
       "         [0.8503, 0.7009, 0.0691],\n",
       "         [0.8888, 0.9170, 0.4282]],\n",
       "\n",
       "        [[0.3776, 0.3869, 0.5531],\n",
       "         [0.1373, 0.3370, 0.3196],\n",
       "         [0.4369, 0.8302, 0.8595],\n",
       "         ...,\n",
       "         [0.2371, 0.7806, 0.2976],\n",
       "         [0.2917, 0.0414, 0.8920],\n",
       "         [0.9222, 0.6185, 0.5648]],\n",
       "\n",
       "        [[0.1801, 0.5697, 0.0667],\n",
       "         [0.0636, 0.4056, 0.2375],\n",
       "         [0.2114, 0.7313, 0.3436],\n",
       "         ...,\n",
       "         [0.3362, 0.4099, 0.4323],\n",
       "         [0.1385, 0.5402, 0.0749],\n",
       "         [0.5183, 0.4183, 0.9181]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.2513, 0.5210, 0.0654],\n",
       "         [0.7032, 0.0176, 0.8018],\n",
       "         [0.9246, 0.1692, 0.7686],\n",
       "         ...,\n",
       "         [0.5583, 0.6399, 0.4882],\n",
       "         [0.5221, 0.2273, 0.8638],\n",
       "         [0.0071, 0.0493, 0.8369]],\n",
       "\n",
       "        [[0.1106, 0.1553, 0.0501],\n",
       "         [0.8853, 0.0626, 0.0832],\n",
       "         [0.8325, 0.4393, 0.2078],\n",
       "         ...,\n",
       "         [0.5126, 0.5504, 0.1211],\n",
       "         [0.1301, 0.4833, 0.3582],\n",
       "         [0.2920, 0.3883, 0.1994]],\n",
       "\n",
       "        [[0.6077, 0.8308, 0.2773],\n",
       "         [0.2580, 0.2910, 0.2618],\n",
       "         [0.1058, 0.9376, 0.0633],\n",
       "         ...,\n",
       "         [0.2683, 0.2466, 0.8661],\n",
       "         [0.4393, 0.7816, 0.9061],\n",
       "         [0.4890, 0.5988, 0.8590]]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a random tensor to an image tensor\n",
    "random_size_image_tensor = torch.rand(size = (224, 224, 3)) # height, width, color channels\n",
    "random_size_image_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([224, 224, 3])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_size_image_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_size_image_tensor.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zeros and Ones Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a tensor of all zeros\n",
    "zeros = torch.zeros(3, 4)\n",
    "zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros*random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating tensor of all ones\n",
    "ones = torch.ones(3, 4)\n",
    "ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a RANGE OF TENSORS and TENSORS-LIKE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use Torch.range()\n",
    "torch.arange(0, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(start = 0, end = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  0,   5,  10,  15,  20,  25,  30,  35,  40,  45,  50,  55,  60,  65,\n",
       "         70,  75,  80,  85,  90,  95, 100, 105, 110, 115, 120, 125, 130, 135,\n",
       "        140, 145, 150, 155, 160, 165, 170, 175, 180, 185, 190, 195, 200, 205,\n",
       "        210, 215, 220, 225, 230, 235, 240, 245, 250, 255, 260, 265, 270, 275,\n",
       "        280, 285, 290, 295, 300, 305, 310, 315, 320, 325, 330, 335, 340, 345,\n",
       "        350, 355, 360, 365, 370, 375, 380, 385, 390, 395, 400, 405, 410, 415,\n",
       "        420, 425, 430, 435, 440, 445, 450, 455, 460, 465, 470, 475, 480, 485,\n",
       "        490, 495, 500, 505, 510, 515, 520, 525, 530, 535, 540, 545, 550, 555,\n",
       "        560, 565, 570, 575, 580, 585, 590, 595, 600, 605, 610, 615, 620, 625,\n",
       "        630, 635, 640, 645, 650, 655, 660, 665, 670, 675, 680, 685, 690, 695,\n",
       "        700, 705, 710, 715, 720, 725, 730, 735, 740, 745, 750, 755, 760, 765,\n",
       "        770, 775, 780, 785, 790, 795, 800, 805, 810, 815, 820, 825, 830, 835,\n",
       "        840, 845, 850, 855, 860, 865, 870, 875, 880, 885, 890, 895, 900, 905,\n",
       "        910, 915, 920, 925, 930, 935, 940, 945, 950, 955, 960, 965, 970, 975,\n",
       "        980, 985, 990, 995])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(start=0, end=1000, step=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a range -\n",
    "one_to_ten = torch.arange(1, 11, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now make a similar shape tensor with ZEROS in it\n",
    "ten_zeros = torch.zeros_like( input = one_to_ten )\n",
    "ten_zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# similarly create a similar shape tensor with only ones\n",
    "ten_ones = torch.ones_like( input = one_to_ten)\n",
    "ten_ones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor Datatypes\n",
    "\n",
    "**Note**: Tensor datatypes is one of the 3 big errors that you will run into while using PyTorch for deep learning:\n",
    "1. Tensor not right datatype\n",
    "2. Tensor not right shape\n",
    "3. Tensor not on the right device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 6., 9.])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Float 32 Tensor\n",
    "float_32_tensor = torch.tensor([3.0, 6.0, 9.0], dtype=None)\n",
    "float_32_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_32_tensor.dtype   # even if dtype = None, default tensor data type is Float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4., 6., 8.], dtype=torch.float16)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_float = torch.tensor([4.0, 6.0, 8.0], dtype = torch.float16)\n",
    "new_float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float16"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_float.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3.], requires_grad=True)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_float = torch.tensor([1.0, 2.0, 3.0],\n",
    "                              dtype = None,  # what datatype is the tensor (eg. float-32, float-16)\n",
    "                              device = None,\n",
    "                              requires_grad = True)\n",
    "complete_float"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting information from a tensor\n",
    "1. Tensor not right datatype = to do get datatype from a tensor using `tensor.dtype`.\n",
    "2. Tensor not right shape = to do get shape from a tensor using `tensor.shape`.  (can also use `tensor.size()`, only difference is that `tensor.size()` is a function whereas `tensor.shape` is an attribute)\n",
    "3. Tensor not on the right device = to do get device from tensor using `tensor.device`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6428, 0.2685, 0.7768, 0.7122],\n",
       "        [0.7310, 0.3244, 0.7007, 0.8333],\n",
       "        [0.8488, 0.4975, 0.5005, 0.4285]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a random tensor\n",
    "some_tensor = torch.rand(3, 4)\n",
    "some_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6428, 0.2685, 0.7768, 0.7122],\n",
      "        [0.7310, 0.3244, 0.7007, 0.8333],\n",
      "        [0.8488, 0.4975, 0.5005, 0.4285]])\n",
      "Datatype of the tensor: torch.float32\n",
      "Shape of the tensor: torch.Size([3, 4])\n",
      "Device of the tensor: cpu\n"
     ]
    }
   ],
   "source": [
    "# Find out the details about the tensor\n",
    "print(some_tensor)\n",
    "print(f\"Datatype of the tensor: {some_tensor.dtype}\")\n",
    "print(f\"Shape of the tensor: {some_tensor.shape}\")\n",
    "print(f\"Device of the tensor: {some_tensor.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manipulating Tensors\n",
    "\n",
    "Tensor Operations Include:\n",
    "* Addition\n",
    "* Subtraction\n",
    "* Multiplication (element-wise)\n",
    "* Division\n",
    "* Matrix Multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Tensor and add 10 to it\n",
    "tensor = torch.tensor([1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11, 12, 13])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add 10 to the tensor\n",
    "tensor = tensor + 10\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiply the tensor with 10\n",
    "tensor = tensor * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([110, 120, 130])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([100, 110, 120])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Subtract 10 from the tensor\n",
    "tensor = tensor - 10\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1000, 1100, 1200])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using pyTorch in-built funtions\n",
    "torch.mul(tensor, 10)     # does not modify the original tensor, returns a new one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([200, 210, 220])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.add(tensor, 100)    # similary this also does not modify the original tensor and instead returns a new one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix Multiplication\n",
    "\n",
    "Two main types of multiplication is used in neural networks and deep learning: \n",
    "1. Element-wise multiplication\n",
    "2. Matrix Multiplication (dot product)\n",
    "\n",
    "There are two main rules that matrix multiplication must satisfy:\n",
    "1. The **inner dimensions** must match\n",
    "* `(3, 2)` @ `(3, 2)` won't work.\n",
    "* `(2, 3)` @ `(3, 2)` will work.\n",
    "* `(3, 2)` @ `(2, 3)` will work.\n",
    "\n",
    "2. The resulting matrix has a shape of **outer dimensions**:\n",
    "* `(2, 3)` @ `(3, 2)` --> `(2, 2)`\n",
    "* `(3, 2)` @ `(2, 3)` --> `(2, 2)`\n",
    "\n",
    "`@` is another way for matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([100, 110, 120]) * tensor([100, 110, 120])\n",
      "Equals: tensor([10000, 12100, 14400])\n"
     ]
    }
   ],
   "source": [
    "# Element-wise multiplication\n",
    "print(tensor, \"*\",  tensor)\n",
    "print(f\"Equals: {tensor * tensor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(36500)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix Multiplication\n",
    "torch.matmul(tensor, tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(36500)\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 2.45 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "value = 0\n",
    "for i in range(len(tensor)):\n",
    "    value += tensor[i] * tensor[i]\n",
    "print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(36500)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "torch.matmul(tensor, tensor)    #the matrix multiplication function of torch is much faster than the traditional way of matrix multiplication."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One of the most commong errors in deep learning is SHAPE ERRORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[52], line 10\u001b[0m\n\u001b[0;32m      2\u001b[0m tensor_A \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([[\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m],\n\u001b[0;32m      3\u001b[0m                          [\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m],\n\u001b[0;32m      4\u001b[0m                          [\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m6\u001b[39m]])\n\u001b[0;32m      6\u001b[0m tensor_B \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([[\u001b[38;5;241m7\u001b[39m, \u001b[38;5;241m10\u001b[39m],\n\u001b[0;32m      7\u001b[0m                          [\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m11\u001b[39m],\n\u001b[0;32m      8\u001b[0m                          [\u001b[38;5;241m9\u001b[39m, \u001b[38;5;241m12\u001b[39m]])\n\u001b[1;32m---> 10\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor_A\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_B\u001b[49m\u001b[43m)\u001b[49m   \u001b[38;5;66;03m# torch.mm() is the same as torch.matmul()\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m## GIVES SHAPE ERROR\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)"
     ]
    }
   ],
   "source": [
    "# Shapes for matrix multiplication\n",
    "tensor_A = torch.tensor([[1, 2],\n",
    "                         [3, 4],\n",
    "                         [5, 6]])\n",
    "\n",
    "tensor_B = torch.tensor([[7, 10],\n",
    "                         [8, 11],\n",
    "                         [9, 12]])\n",
    "\n",
    "torch.mm(tensor_A, tensor_B)   # torch.mm() is the same as torch.matmul()\n",
    "## GIVES SHAPE ERROR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fix our shape errors, we can convert one of the tensors using **transpose**.\n",
    "\n",
    "A **transpose** switches the axes or the dimensions of a given tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7, 10],\n",
       "        [ 8, 11],\n",
       "        [ 9, 12]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7,  8,  9],\n",
       "        [10, 11, 12]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_B.T     # transposes the tensor_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 27,  30,  33],\n",
       "        [ 61,  68,  75],\n",
       "        [ 95, 106, 117]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mm(tensor_A, tensor_B.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding min, max, mean, sum etc (Tensor Aggregation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a Tensor\n",
    "x = torch.arange(0, 100, 10)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0), tensor(0))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding the minimum\n",
    "torch.min(x), x.min()    # any of the two can be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(90), tensor(90))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding the maximum\n",
    "torch.max(x), x.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mean(): could not infer output dtype. Input dtype must be either a floating point or complex dtype. Got: Long",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[59], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Finding the mean\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# this gives the DATATYPE ERROR (one of the 3 major errors)\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# given tensor has the datatype LONG (mean does not work on LONG)\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mean(): could not infer output dtype. Input dtype must be either a floating point or complex dtype. Got: Long"
     ]
    }
   ],
   "source": [
    "# Finding the mean\n",
    "torch.mean(x)\n",
    "\n",
    "# this gives the DATATYPE ERROR (one of the 3 major errors)\n",
    "# given tensor has the datatype LONG (mean does not work on LONG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(45.), tensor(45.))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The torch.mean() function requires a tensor of datatype float32\n",
    "torch.mean(x.type(dtype=torch.float32)), x.type(torch.float32).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(450), tensor(450))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding the sum\n",
    "torch.sum(x), x.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding the positional min and max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.argmin() # gives the index of the minimum element in the tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.argmax() # gives the index of the maximum element in the tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshaping, stacking, squeezing and unsqueezing tensors\n",
    "\n",
    "* Reshaping - Reshapes an input tensor to a defined shape.\n",
    "* View - Return a view of an input tensor of certain shape but keep the same memory as the original tensor.\n",
    "* Stacking - Combine multiple tensors on top of each other (vstack) or side by side (hstack).\n",
    "* Squeeze - Removes all `1` dimensions from a tensor.\n",
    "* Unsqueeze - Add a `1` dimension to a target tensor.\n",
    "* Permute - Return a view of the input with dimensions permuted (swapped) in a certain way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.]), torch.Size([10]))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new tensor\n",
    "new_tensor = torch.arange(1., 11.)\n",
    "new_tensor, new_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add an extra dimension\n",
    "tensor_reshaped = new_tensor.reshape(1, 10)\n",
    "tensor_reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  2.],\n",
       "        [ 3.,  4.],\n",
       "        [ 5.,  6.],\n",
       "        [ 7.,  8.],\n",
       "        [ 9., 10.]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_reshaped_again = new_tensor.reshape(5, 2)\n",
    "tensor_reshaped_again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Changing the VIEW of the tensor\n",
    "view_tensor = new_tensor.view(1, 10)\n",
    "view_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 5.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.]]),\n",
       " tensor([ 5.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.]))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# changind the view changes the original tensor, because view of a tensor shares the same memory as the original tensor.\n",
    "view_tensor[:, 0] = 5\n",
    "view_tensor, new_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.],\n",
       "        [ 5.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.],\n",
       "        [ 5.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.],\n",
       "        [ 5.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stack tensors on top of each other\n",
    "new_tensor_stacked = torch.stack([new_tensor, new_tensor, new_tensor, new_tensor], dim=-2)\n",
    "new_tensor_stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1, 2, 3, 4, 5]), tensor([ 6,  7,  8,  9, 10]))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using VERTICAL STACK OR TORCH.VSTACK\n",
    "p = torch.arange(1, 6)\n",
    "q = torch.arange(6, 11)\n",
    "p, q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  2,  3,  4,  5],\n",
       "        [ 6,  7,  8,  9, 10]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verticall stacking the tensors\n",
    "torch.vstack((p, q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using HORIZONTAL STACKING OR TORCH.HSTACK\n",
    "torch.hstack((p, q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[[0., 0.]],\n",
       "\n",
       "          [[0., 0.]]]],\n",
       "\n",
       "\n",
       "\n",
       "        [[[[0., 0.]],\n",
       "\n",
       "          [[0., 0.]]]]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SQUEEZING \n",
    "some_tensor = torch.zeros(2, 1, 2, 1, 2)\n",
    "some_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensor([ # 1st dimension with 2 subgroups\n",
    "#         [ # first sub-group with only 1 subgroup inside 2nd DIMENSION\n",
    "#             [ # 3rd dimension with 2 sub groups\n",
    "#                 [ # first subgroup 4th DIMENSION\n",
    "#                     [0., 0.] # 5th DIMENSION\n",
    "#                 ],\n",
    "\n",
    "#                 [ # second subgroup\n",
    "#                     [0., 0.]\n",
    "#                 ]\n",
    "#             ]\n",
    "#         ],\n",
    "\n",
    "#         [ # second subgroup with only one subgroup inside 2nd DIMESION\n",
    "#             [ # 3rd dimension with two subgroups\n",
    "#                 [ # first sub group 4th DIMENSION\n",
    "#                     [0., 0.] # 5th DIMENSION\n",
    "#                 ],\n",
    "#                 [ # second subgroup\n",
    "#                     [0., 0.]\n",
    "#                 ]\n",
    "#             ]\n",
    "#         ]\n",
    "#     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0.],\n",
       "         [0., 0.]],\n",
       "\n",
       "        [[0., 0.],\n",
       "         [0., 0.]]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Squeezing\n",
    "some_tensor.squeeze()\n",
    "\n",
    "# removes all single dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example of squeezing\n",
    "ek_tensor = torch.arange(1, 11)\n",
    "ek_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ek_tensor_reshape = ek_tensor.reshape([1, 10])\n",
    "ek_tensor_reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Tensor: tensor([[ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10]])\n",
      "Original Tensor Shape: torch.Size([1, 10])\n",
      "\n",
      "Squeezed Tensor: tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])\n",
      "Squeezed Tensor Shape: torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Original Tensor: {ek_tensor_reshape}\")\n",
    "print(f\"Original Tensor Shape: {ek_tensor_reshape.shape}\")\n",
    "\n",
    "print(f\"\\nSqueezed Tensor: {ek_tensor_reshape.squeeze()}\")\n",
    "print(f\"Squeezed Tensor Shape: {ek_tensor_reshape.squeeze().shape}\")\n",
    "\n",
    "\n",
    "# as we can see that the tensor dimension was [1, 10] but after squeezing the tensor the single dimensions were removed, and the tensor has a dimension of only [10]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10]), torch.Size([10]))"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making a new tensor for the squeezed tensor\n",
    "squeezed_tensor = ek_tensor_reshape.squeeze()\n",
    "squeezed_tensor, squeezed_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1],\n",
       "         [ 2],\n",
       "         [ 3],\n",
       "         [ 4],\n",
       "         [ 5],\n",
       "         [ 6],\n",
       "         [ 7],\n",
       "         [ 8],\n",
       "         [ 9],\n",
       "         [10]]),\n",
       " torch.Size([10, 1]))"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unsqueezing the squeezed tensor  -  Adds a single dimension to the target tensor at a given specific dimension.\n",
    "unsqueezed_tensor = squeezed_tensor.unsqueeze(dim=1)\n",
    "unsqueezed_tensor, unsqueezed_tensor.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous Tensor (Squeezed): tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])\n",
      "Previous Tensor (Squeezed) Shape: torch.Size([10])\n",
      "\n",
      "Unsqueezed Tensor: tensor([[ 1],\n",
      "        [ 2],\n",
      "        [ 3],\n",
      "        [ 4],\n",
      "        [ 5],\n",
      "        [ 6],\n",
      "        [ 7],\n",
      "        [ 8],\n",
      "        [ 9],\n",
      "        [10]])\n",
      "Unsqueezed Tensor Shape: torch.Size([10, 1])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Previous Tensor (Squeezed): {squeezed_tensor}\")\n",
    "print(f\"Previous Tensor (Squeezed) Shape: {squeezed_tensor.shape}\")\n",
    "\n",
    "print(f\"\\nUnsqueezed Tensor: {unsqueezed_tensor}\")\n",
    "print(f\"Unsqueezed Tensor Shape: {unsqueezed_tensor.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Tensor Shape: torch.Size([225, 224, 3])\n",
      "Permuted Tensor Shape: torch.Size([3, 225, 224])\n"
     ]
    }
   ],
   "source": [
    "# PERMUTE - rearrages the dimensions of target tensor tensor in a specified order\n",
    "original_tensor = torch.rand((225, 224, 3))     # [height, width, colour_channels]\n",
    "print(f\"Original Tensor Shape: {original_tensor.shape}\")\n",
    "\n",
    "# rearrange the tensor --->  0 -> 1, 1 -> 2, 2 -> 1\n",
    "original_tensor_permuted = original_tensor.permute(2, 0, 1)\n",
    "print(f\"Permuted Tensor Shape: {original_tensor_permuted.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_tensor[0, 0, 0] = 23456"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(23456.), tensor(23456.))"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_tensor[0, 0, 0], original_tensor_permuted[0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
